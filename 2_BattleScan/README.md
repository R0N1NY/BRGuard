# BattleScan

This repository contains instructions for running the **BattleScan** subsystem. The process is outlined in the following steps:

## 1. Dataset Preparation

For the BattleScan dataset, We need to ensure that the division of the dataset is consistent with MatchScope subsystem. Therefore we need to refer to the previous dataset for segmentation.

```sh
$ python gen_data.py ../ExtractData/BlackEigenvalue_battleBehavior.csv ../ExtractData/WhiteEigenvalue_battleBehavior.csv ../1_MatchScope/dataset
```

The first two options are the file paths to the cheater battle behavior feature data and the normal player battle behavior feature data generated by the previous step (**Preprocess**). And the third option is the folder path to subsystem MatchScope's dataset.

Then, we can get the `dataset` folder with the same file structure as the MatchScope dataset.

```markdown
.
└── 2_BattleScan
    ├── dataset/
    │   ├── mobile/
    │   │   ├── final_test.csv
    │   │   ├── final_train.csv
    │   │   ├── final_val.csv
    │   └── pc/
    │       ├── final_test.csv
    │       ├── final_train.csv
    │       └── final_val.csv
    └── other folders and scripts ...
```

## 2. Downsampling Training Data

Due to imbalanced positive and negative samples in the dataset, it's essential to downsample the training set for effective model training:

```sh
$ python downsample_train.py dataset/mobile/final_train.csv
```

This script generates several sub-training datasets in the `dataset/mobile` folder based on the ratio of positive to negative samples. If you want to train the `pc` platform, just modify the `dataset/mobile/final_train.csv` option to `dataset/pc/final_train.csv`.

##### TBD

## 3. Training Models

To save time, a script is provided for parallel training of all models. This script will use seven different classification models, each trained on the sub-training datasets in the `dataset` folder:

```sh
$ ./train.sh 13 mobile 2
```

The first option should be the same as the number of sub-training sets, e.g. for `mobile` it is `13` and for `pc` it is `4`, just check the corresponding dataset.
The second option is the platform type of the training data.
And the third option is the maximum number of threads to run a **single** python script. We recommend setting smaller values during training, as there may be many python scripts running in parallel.

For training individual models, refer to the scripts in the `training_scripts` folder. The training models will be saved in a newly created `PlatformType/models` folder. Some other training result data will also be stored in the corresponding newly created folder.

## 4. Testing Models

After training, test the models using the test script, which is similar to the training script. This script will load all trained models:

```sh
$ ./test.sh 13 mobile
```

The options here are the same as the first and second options of the training script (`train.sh`).
For individual model testing, refer to the `test_scripts` folder. The test results will be saved in a newly created `test` folder, and some results data will be saved in the newly created `results/test_results` folder.

## 5. Evaluating Predictions

First, enter the `eval` folder and run the `merge_pred.py` script to merge all prediction results. You can choose to merge both validation and test results or just one of them (add the option `test` or `val`):

```sh
$ cd eval && python merge_pred.py mobile
```

The option is the platform type (`mobile` or `pc`) of your evaluation target.
After running the script, you will obtain the final prediction results for the MatchScope subsystem in the specified folder (test/val). Then, run the `evaluation.py` script to obtain the model's evaluation metrics, which will be displayed in the terminal and saved in the respective folder:

```sh
$ python evaluation.py mobile
```

Similar to the merge script, selecting the platform type and you can also choose to evaluate results for a specific dataset, just add the option `test` or `val`.