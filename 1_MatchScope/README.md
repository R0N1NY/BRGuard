# MatchScope

This repository contains instructions for running the **MatchScope** subsystem. The process is outlined in the following steps:

## 1. Dataset Preparation

After preprocessing, we extract MatchScope feature data and divide the dataset into training sets, test sets, and validation sets.

```sh
$ python gen_data.py ../ExtractData/BlackEigenvalue_matchBehavior.csv ../ExtractData/WhiteEigenvalue_matchBehavior.csv
```

The options are the file paths to the cheater match behavior feature data and the normal player match behavior feature data generated by the previous step (**Preprocess**).

Then we can get the `dataset` folder, which distinguishes two categories of data based on the player's gaming platform, namely `pc` and `mobile`. So, the file structure of the dataset folder should be as follows:

```markdown
.
└── 1_MatchScope
    ├── dataset/
    │   ├── mobile/
    │   │   ├── final_test.csv
    │   │   ├── final_train.csv
    │   │   ├── final_val.csv
    │   └── pc/
    │       ├── final_test.csv
    │       ├── final_train.csv
    │       └── final_val.csv
    └── other folders and scripts ...
```

## 2. Downsampling Training Data

Due to imbalanced positive and negative samples in the dataset, it's essential to downsample the training set for effective model training:

```sh
$ python downsample_train.py dataset/mobile/final_train.csv
```

This script generates several sub-training datasets in the `dataset/mobile` folder based on the ratio of positive to negative samples. If you want to train the `pc` platform, just modify the `dataset/mobile/final_train.csv` option to `dataset/pc/final_train.csv`.

## 3. Training Models

To save time, a script is provided for parallel training of all models. This script will use seven different classification models, each trained on the sub-training datasets in the `dataset` folder:

```sh
$ ./train.sh 13 mobile 2
```

The first option should be the same as the number of sub-training sets, e.g. for `mobile` it is `13` and for `pc` it is `4`, just check the corresponding dataset.
The second option is the platform type of the training data.
And the third option is the maximum number of threads to run a **single** python script. For example here, the mobile platform contains **13** sub-training datasets, so it will run 13 python scripts in parallel, and allocate 2 threads each. We recommend setting smaller values during training, as there may be many python scripts running in parallel.

For training individual models, refer to the scripts in the `training_scripts` folder. The training models will be saved in a newly created `PlatformType/models` folder. Some other training result data will also be stored in the corresponding newly created folder.

## 4. Testing Models

After training, test the models using the test script, which is similar to the training script. This script will load all trained models:

```sh
$ ./test.sh 13 mobile
```

The options here are the same as the first and second options of the training script (`train.sh`).
For individual model testing, refer to the `test_scripts` folder. The test results will be saved in a newly created `test` folder, and some results data will be saved in the newly created `results/test_results` folder.

## 5. Evaluating Predictions

First, enter the `eval` folder and run the `merge_pred.py` script to merge all prediction results. You can choose to merge both validation and test results or just one of them (add the option `test` or `val`):

```sh
$ cd eval && python merge_pred.py mobile
```

The option is the platform type (`mobile` or `pc`) of your evaluation target.
After running the script, you will obtain the final prediction results for the MatchScope subsystem in the specified folder (test/val). Then, run the `evaluation.py` script to obtain the model's evaluation metrics, which will be displayed in the terminal and saved in the respective folder:

```sh
$ python evaluation.py mobile
```

Similar to the merge script, selecting the platform type and you can also choose to evaluate results for a specific dataset, just add the option `test` or `val`.